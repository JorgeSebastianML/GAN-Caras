{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np                # funciones numéricas (arrays, matrices, etc.)\n",
    "import matplotlib.pyplot as plt   # funciones para representación gráfica\n",
    "#from skimage import io\n",
    " \n",
    "carpeta = \"../1Dataset/\"\n",
    "cont = 0\n",
    "width = 28\n",
    "height = 28\n",
    "for archivo in os.listdir(carpeta):\n",
    "    cont = cont + 1\n",
    "I = np.zeros([cont, width, height])\n",
    "cont = 0\n",
    "for archivo in os.listdir(carpeta):\n",
    "    #print(os.path.join(carpeta,archivo))\n",
    "    foto = Image.open(os.path.join(carpeta,archivo))\n",
    "    datos = foto.getdata()\n",
    " \n",
    "    #para el calculo del promedio se utilizara la division entera con el operador de division doble \"//\" para evitar decimales\n",
    "\n",
    "    promedio = [(datos[x][0] + datos[x][1] + datos[x][2]) // 3 for x in range(len(datos))]\n",
    "    imagen_gris = Image.new('L', foto.size)\n",
    "    imagen_gris.putdata(promedio)\n",
    "    imagen_gris2 = imagen_gris.resize((width, height), Image.NEAREST) \n",
    "    I[cont, :, :] = imagen_gris2\n",
    "    #I[cont, :, :] = io.imread(os.path.join(carpeta,archivo))\n",
    "    cont = cont + 1\n",
    "    #plt.imshow(I)\n",
    "    \n",
    "\n",
    "carpeta = \"../2Dataset/\"\n",
    "cont2 = 0\n",
    "for archivo in os.listdir(carpeta):\n",
    "    cont2 = cont2 + 1\n",
    "I2 = np.zeros([cont2, width, height])\n",
    "cont2 = 0\n",
    "for archivo in os.listdir(carpeta):\n",
    "    #print(os.path.join(carpeta,archivo))\n",
    "    \n",
    "    if np.random.random() < 0.12:\n",
    "        try: \n",
    "            foto2 = Image.open(os.path.join(carpeta,archivo))\n",
    "            datos2 = foto2.getdata()\n",
    "            #para el calculo del promedio se utilizara la division entera con el operador de division doble \"//\" para evitar decimales\n",
    "            promedio2 = [(datos2[x][0] + datos2[x][1] + datos2[x][2]) // 3 for x in range(len(datos2))]\n",
    "            imagen_gris3 = Image.new('L', foto2.size)\n",
    "            imagen_gris3.putdata(promedio2)\n",
    "            imagen_gris4 = imagen_gris3.resize((width, height), Image.NEAREST) \n",
    "            I2[cont2, :, :] = imagen_gris4\n",
    "            #I[cont, :, :] = io.imread(os.path.join(carpeta,archivo))\n",
    "            cont2 = cont2 + 1\n",
    "            #plt.imshow(I)\n",
    "        except:\n",
    "            print(\"Imagen Blanco y negro, \" + archivo)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I3 = np.zeros([cont, width * height])\n",
    "for i in range(0, cont):\n",
    "        I3[i, :] = I[i, :, :].ravel()\n",
    "I4 = np.zeros([cont2, width * height])\n",
    "for i in range(0, cont2):\n",
    "        I4[i, :] = I2[i, :, :].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import svm\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Apply standard scaler to output from resnet50\n",
    "X_train = I3[:10000, :]\n",
    "X_test = I3[10001:, :]\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train = ss.transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "X_test2 = ss.transform(I4)\n",
    "# Take PCA to reduce feature space dimensionality\n",
    "pca = PCA(n_components=400, whiten=True)\n",
    "pca = pca.fit(X_train)\n",
    "print('Explained variance percentage = %0.2f' % sum(pca.explained_variance_ratio_))\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "X_test2 = pca.transform(X_test2)\n",
    "# Train classifier and obtain predictions for OC-SVM\n",
    "oc_svm_clf = svm.OneClassSVM(gamma='auto', kernel='rbf', nu=0.27)  # Obtained using grid search\n",
    "\n",
    "if_clf = IsolationForest(bootstrap =True, n_jobs = -1, contamination=0.27, max_features=1.0, max_samples=1.0, n_estimators=400)  # Obtained using grid search\n",
    "\n",
    "oc_svm_clf.fit(X_train)\n",
    "\n",
    "if_clf.fit(X_train)\n",
    "\n",
    "oc_svm_preds = oc_svm_clf.predict(X_test)\n",
    "\n",
    "if_preds = if_clf.predict(X_test)\n",
    "\n",
    "oc_svm_preds2 = oc_svm_clf.predict(X_test2)\n",
    "\n",
    "if_preds2 = if_clf.predict(X_test2)\n",
    "\n",
    "Accuracy = 0\n",
    "matrix_C = np.zeros([2, 2])\n",
    "for X2 in range(0, if_preds.shape[0]):\n",
    "    if if_preds[X2]==1: #Verdaderos Positivos\n",
    "        Accuracy = Accuracy + 1\n",
    "        matrix_C[0, 0] = matrix_C[0, 0] + 1 \n",
    "    else:\n",
    "        matrix_C[0, 1] = matrix_C[0, 1] + 1 \n",
    "    \n",
    "for X2 in range(0, if_preds2.shape[0]):\n",
    "    if if_preds2[X2]==-1: #Verdaderos Negativos\n",
    "        Accuracy = Accuracy + 1\n",
    "        matrix_C[1, 1] = matrix_C[1, 1] + 1 \n",
    "    else:\n",
    "        matrix_C[1, 0] = matrix_C[1, 0] + 1 \n",
    "Accuracy = Accuracy / (if_preds.shape[0]+if_preds2.shape[0]); \n",
    "print(\"Accurracy Isolation Forest: \" + str(Accuracy))\n",
    "\n",
    "Accuracy2 = 0\n",
    "matrix_C2 = np.zeros([2, 2])\n",
    "for X2 in range(0, oc_svm_preds.shape[0]):\n",
    "    if oc_svm_preds[X2]==1: #Verdaderos Positivos\n",
    "        Accuracy2 = Accuracy2 + 1\n",
    "        matrix_C2[0, 0] = matrix_C2[0, 0] + 1 \n",
    "    else:\n",
    "        matrix_C2[0, 1] = matrix_C2[0, 1] + 1 \n",
    "for X2 in range(0, oc_svm_preds2.shape[0]):\n",
    "    if oc_svm_preds2[X2]==-1: #Verdaderos Negativos\n",
    "        Accuracy2 = Accuracy2 + 1\n",
    "        matrix_C2[1, 1] = matrix_C2[1, 1] + 1 \n",
    "    else:\n",
    "        matrix_C2[1, 0] = matrix_C2[1, 0] + 1 \n",
    "Accuracy2 = Accuracy2 / (oc_svm_preds.shape[0] + oc_svm_preds2.shape[0])\n",
    "print(\"Accurracy SVM \" + str(Accuracy2))\n",
    "\n",
    "vFileName = 'Clasificador_de_caras.joblib.pkl'\n",
    "vFilePathRelative = 'Save Models/' + vFileName\n",
    "vDirPath = os.path.dirname(os.path.realpath(vFilePathRelative))\n",
    "vFilePath = os.path.join(vDirPath, vFileName)\n",
    "if Accuracy > Accuracy2:\n",
    "    vDump = joblib.dump(if_clf, vFilePathRelative, compress = 9)\n",
    "else: \n",
    "    vDump = joblib.dump(oc_svm_clf, vFilePathRelative, compress = 9)\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_[:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "\n",
    "fid = open('Save Models/Clasificador_de_caras.joblib.pkl', 'rb')\n",
    "joblib_Model = joblib.load(fid)\n",
    "PrediccionTest = joblib_Model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrediccionTest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
