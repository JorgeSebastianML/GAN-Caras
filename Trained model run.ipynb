{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from matplotlib import pyplot\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "import os\n",
    "import shutil\n",
    "import helper1\n",
    "import problem_unittests as tests\n",
    "import cv2 \n",
    "from PIL import Image\n",
    "import numpy as np                # funciones numéricas (arrays, matrices, etc.)\n",
    "import matplotlib.pyplot as plt   # funciones para representación gráfica\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy import inf\n",
    "import scipy.misc\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "\n",
    "    \n",
    "# Se crea la funcion que inicializa los placeholder del grafo del tensor flow\n",
    "def model_inputs(image_width, image_height, image_channels, z_dim):\n",
    "    \"\"\"\n",
    "    Se crean las entradas del modelo\n",
    "    :param image_width: El ancho de la imagen  --> 28\n",
    "    :param image_height: La altura de la imagen --> 28\n",
    "    :param image_channels: El numero de capas de la imagen RGB --> 3\n",
    "    :param z_dim: La dimension de z --> 100\n",
    "    :return: Una tupla de (Un tensor de salidas reales, un tensor con los datos de z, la tasa de aprendizaje)\n",
    "    \"\"\"\n",
    "    \n",
    "    tensor_real_imput_img = tf.placeholder(tf.float32, shape=(None, image_width, image_height, image_channels))\n",
    "    tensor_z_data = tf.placeholder(tf.float32, shape=(None, z_dim))\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "\n",
    "    return (tensor_real_imput_img, tensor_z_data, learning_rate)\n",
    "\n",
    "# Se crea la funcion que genera el discriminador de la red GAN\n",
    "def discriminator(images, reuse=False, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Se crea el discriminador de la red\n",
    "    :param images: Tensor con la entrada de la imagen(es)--> Tensor(\"Placeholder:0\", Tamaño=(?, 28, 28, 3), dtype=float32)\n",
    "    :param reuse: Booleano si los pesos deben ser reutilizados.\n",
    "    :return: Una tupla de (Un tensor de salida del discriminador, Un tensor logits del discriminador)\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # input layer --> 28, 28, 3\n",
    "        \n",
    "        start_dim = 28*2\n",
    "        kernel_sz = 5\n",
    "        strides = 2\n",
    "\n",
    "        layer_0 = tf.layers.conv2d(images, start_dim, kernel_sz, strides=strides, padding='same', \n",
    "                                   kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=True,\n",
    "                                                                                          seed=None,\n",
    "                                                                                          dtype=tf.float32\n",
    "                                                                                          )\n",
    "                                  )\n",
    "        relu_0 = tf.maximum(alpha * layer_0, layer_0)\n",
    "        #14*14*56\n",
    "        \n",
    "        layer_1 = tf.layers.conv2d(relu_0, start_dim*2, kernel_sz, strides=strides, padding='same')\n",
    "        batchnorm_1 = tf.layers.batch_normalization(layer_1, training=True)\n",
    "        relu_1 = tf.maximum(alpha * batchnorm_1, batchnorm_1)\n",
    "        #  7, 7, 112\n",
    "        \n",
    "        layer_2 = tf.layers.conv2d(relu_1, start_dim*4, kernel_sz, strides=strides, padding='same')\n",
    "        batchnorm_2 = tf.layers.batch_normalization(layer_2, training=True)\n",
    "        relu_2 = tf.maximum(alpha * batchnorm_2, batchnorm_2)\n",
    "        #4, 4, 224\n",
    "        \n",
    "        layer_3 = tf.layers.conv2d(relu_2, start_dim*8, kernel_sz, strides=strides, padding='same')\n",
    "        batchnorm_3 = tf.layers.batch_normalization(layer_2, training=True)\n",
    "        relu_3 = tf.maximum(alpha * batchnorm_3, batchnorm_3)\n",
    "        relu_3_d = tf.nn.dropout(relu_3, 0.8)\n",
    "        #4, 4, 224\n",
    "        \n",
    "        flatten = tf.reshape(relu_3_d, (-1, (start_dim*4)*4*4)) \n",
    "            \n",
    "        logits = tf.layers.dense(flatten, 1)\n",
    "        output = tf.sigmoid(logits)\n",
    "\n",
    "    return (output, logits)\n",
    "\n",
    "# Se crea la funcion que crea el generador de la red GAN\n",
    "def generator(z, out_channel_dim, is_train=True, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Se crea el generador de la Red\n",
    "    :param z: Input z --> Tensor(\"Placeholder:0\", Tamaño=(?, 100), dtype=float32)\n",
    "    :param out_channel_dim: Numero de canales en la capa de salida --> 5\n",
    "    :param is_train: Booleano si el generador está siendo utilizado para entrenamiento.\n",
    "    :return: El tensor de salida del generador\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('generator', reuse=not is_train):\n",
    "        start_dim = 512\n",
    "        kernel_sz = 5\n",
    "        strides = 2\n",
    "\n",
    "        layer_0 = tf.layers.dense(z, 7*7*start_dim)\n",
    "    \n",
    "        layer_0 = tf.reshape(layer_0, (-1, 7, 7, start_dim))\n",
    "        layer_0 = tf.layers.batch_normalization(layer_0, training=is_train)\n",
    "        # 7, 7, 512 \n",
    "      \n",
    "        layer_1 = tf.layers.conv2d_transpose(layer_0, int(start_dim/2), kernel_sz, \n",
    "                                             strides=strides, padding='same', \n",
    "                                             kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=True,\n",
    "                                                                                          seed=None,\n",
    "                                                                                          dtype=tf.float32\n",
    "                                                                                          )\n",
    "                                            )\n",
    "        layer_1 = tf.layers.batch_normalization(layer_1, training=is_train)\n",
    "        relu_1 = tf.maximum(alpha * layer_1, layer_1)\n",
    "        # 14, 14, 256\n",
    "    \n",
    "        layer_2 = tf.layers.conv2d_transpose(layer_1, int(start_dim/4), kernel_sz, strides=strides, padding='same')\n",
    "        layer_2 = tf.layers.batch_normalization(layer_2, training=is_train)\n",
    "        relu_2 = tf. maximum(alpha * layer_2, layer_2)\n",
    "        # 28, 28, 128\n",
    "        \n",
    "        layer_3 = tf.layers.conv2d_transpose(layer_2, int(start_dim/8), kernel_sz, strides=strides, padding='same')\n",
    "        layer_3 = tf.layers.batch_normalization(layer_3, training=is_train)\n",
    "        relu_3 = tf. maximum(alpha * layer_3, layer_3)\n",
    "        relu_3_d = tf.nn.dropout(relu_3, 0.8)\n",
    "        # 28, 28, 128\n",
    "\n",
    "    \n",
    "        logits = tf.layers.conv2d_transpose(relu_3_d, out_channel_dim, kernel_sz, strides=strides, padding='same')\n",
    "        logits = tf.reshape(logits, (-1, 28, 28, out_channel_dim))\n",
    "        # 28, 28, 5\n",
    "        output = tf.tanh(logits)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    \n",
    "def show_generator_output(sess, n_images, input_z, out_channel_dim, image_mode):\n",
    "    \"\"\"\n",
    "    Show example output for the generator\n",
    "    :param sess: TensorFlow session\n",
    "    :param n_images: Number of Images to display\n",
    "    :param input_z: Input Z Tensor\n",
    "    :param out_channel_dim: The number of channels in the output image\n",
    "    :param image_mode: The mode to use for images (\"RGB\" or \"L\")\n",
    "    \"\"\"\n",
    "    sample_directory = './figs' #Directory to save sample images from generator in.\n",
    "    \n",
    "    cmap = None if image_mode == 'RGB' else 'gray'\n",
    "    z_dim = input_z.get_shape().as_list()[-1]\n",
    "    example_z = np.random.uniform(-1, 1, size=[n_images, z_dim])\n",
    "\n",
    "    samples = sess.run(\n",
    "        generator(input_z, out_channel_dim, False),\n",
    "        feed_dict={input_z: example_z})\n",
    "\n",
    "    images_grid = helper1.images_square_grid(samples, image_mode)\n",
    "    pyplot.imshow(images_grid, cmap=cmap)\n",
    "    pyplot.show()\n",
    "    if not os.path.exists(sample_directory):\n",
    "        os.makedirs(sample_directory)\n",
    "    scipy.misc.imsave(sample_directory + '/fig_trained_model'  + '.png', images_grid)\n",
    "    \n",
    "\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "    \n",
    "model_directory = './Train_Models'\n",
    "# Se cierra la secion de tensor flow (si esta abierta)\n",
    "tf.InteractiveSession().close()\n",
    "# Se resetea el grafo\n",
    "tf.reset_default_graph()\n",
    "# Se inicializan los tensores\n",
    "tensor_real_imput_img = tf.placeholder(tf.float32, shape=(None, 28, 28, 3))\n",
    "tensor_z_data = tf.placeholder(tf.float32, shape=(None, 100))\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "# Se carga el generador y el discriminidador\n",
    "GeneratorOutput = generator(tensor_z_data, 3, is_train=True, alpha=0.2)\n",
    "DiscriminationOutput = discriminator(tensor_real_imput_img, reuse=False, alpha=0.2)\n",
    "# Se carga el modelo entrenado \n",
    "saver = tf.train.Saver()\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state(model_directory)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "n_images = 1\n",
    "out_channel_dim = 3\n",
    "image_mode=\"RGB\"\n",
    "# Se genera ruido blanco \n",
    "z_dim = tensor_z_data.get_shape().as_list()[-1]\n",
    "example_z = np.random.uniform(-1, 1, size=[n_images, z_dim])\n",
    "# Se corre la seccion de tensor flow\n",
    "samples = sess.run(\n",
    "    generator(tensor_z_data, out_channel_dim, False),\n",
    "    feed_dict={tensor_z_data: example_z})\n",
    "\n",
    "samples[1,:,:,:]\n",
    "# Se muestra las imagenes generadas\n",
    "show_generator_output(sess, 1, tensor_z_data, 3, image_mode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
