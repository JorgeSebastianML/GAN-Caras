{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from matplotlib import pyplot\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "import os\n",
    "import shutil\n",
    "import helper1\n",
    "import problem_unittests as tests\n",
    "import cv2 \n",
    "from PIL import Image\n",
    "import numpy as np                # funciones numéricas (arrays, matrices, etc.)\n",
    "import matplotlib.pyplot as plt   # funciones para representación gráfica\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy import inf\n",
    "import scipy.misc\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "\n",
    "    \n",
    "# Se crea la funcion que inicializa los placeholder del grafo del tensor flow\n",
    "def model_inputs(image_width, image_height, image_channels, z_dim):\n",
    "    \"\"\"\n",
    "    Se crean las entradas del modelo\n",
    "    :param image_width: El ancho de la imagen  --> 28\n",
    "    :param image_height: La altura de la imagen --> 28\n",
    "    :param image_channels: El numero de capas de la imagen RGB --> 3\n",
    "    :param z_dim: La dimension de z --> 100\n",
    "    :return: Una tupla de (Un tensor de salidas reales, un tensor con los datos de z, la tasa de aprendizaje)\n",
    "    \"\"\"\n",
    "    \n",
    "    tensor_real_imput_img = tf.placeholder(tf.float32, shape=(None, image_width, image_height, image_channels))\n",
    "    tensor_z_data = tf.placeholder(tf.float32, shape=(None, z_dim))\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "\n",
    "    return (tensor_real_imput_img, tensor_z_data, learning_rate)\n",
    "\n",
    "# Se crea la funcion que genera el discriminador de la red GAN\n",
    "def discriminator(images, reuse=False, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Se crea el discriminador de la red\n",
    "    :param images: Tensor con la entrada de la imagen(es)--> Tensor(\"Placeholder:0\", Tamaño=(?, 28, 28, 3), dtype=float32)\n",
    "    :param reuse: Booleano si los pesos deben ser reutilizados.\n",
    "    :return: Una tupla de (Un tensor de salida del discriminador, Un tensor logits del discriminador)\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # input layer --> 28, 28, 3\n",
    "        \n",
    "        start_dim = 28*2\n",
    "        kernel_sz = 5\n",
    "        strides = 2\n",
    "\n",
    "        layer_0 = tf.layers.conv2d(images, start_dim, kernel_sz, strides=strides, padding='same', \n",
    "                                   kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=True,\n",
    "                                                                                          seed=None,\n",
    "                                                                                          dtype=tf.float32\n",
    "                                                                                          )\n",
    "                                  )\n",
    "        relu_0 = tf.maximum(alpha * layer_0, layer_0)\n",
    "        #14*14*56\n",
    "        \n",
    "        layer_1 = tf.layers.conv2d(relu_0, start_dim*2, kernel_sz, strides=strides, padding='same')\n",
    "        batchnorm_1 = tf.layers.batch_normalization(layer_1, training=True)\n",
    "        relu_1 = tf.maximum(alpha * batchnorm_1, batchnorm_1)\n",
    "        #  7, 7, 112\n",
    "        \n",
    "        layer_2 = tf.layers.conv2d(relu_1, start_dim*4, kernel_sz, strides=strides, padding='same')\n",
    "        batchnorm_2 = tf.layers.batch_normalization(layer_2, training=True)\n",
    "        relu_2 = tf.maximum(alpha * batchnorm_2, batchnorm_2)\n",
    "        #4, 4, 224\n",
    "        \n",
    "        layer_3 = tf.layers.conv2d(relu_2, start_dim*8, kernel_sz, strides=strides, padding='same')\n",
    "        batchnorm_3 = tf.layers.batch_normalization(layer_2, training=True)\n",
    "        relu_3 = tf.maximum(alpha * batchnorm_3, batchnorm_3)\n",
    "        relu_3_d = tf.nn.dropout(relu_3, 0.8)\n",
    "        #4, 4, 224\n",
    "        \n",
    "        flatten = tf.reshape(relu_3_d, (-1, (start_dim*4)*4*4)) \n",
    "            \n",
    "        logits = tf.layers.dense(flatten, 1)\n",
    "        output = tf.sigmoid(logits)\n",
    "\n",
    "    return (output, logits)\n",
    "\n",
    "# Se crea la funcion que crea el generador de la red GAN\n",
    "def generator(z, out_channel_dim, is_train=True, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Se crea el generador de la Red\n",
    "    :param z: Input z --> Tensor(\"Placeholder:0\", Tamaño=(?, 100), dtype=float32)\n",
    "    :param out_channel_dim: Numero de canales en la capa de salida --> 5\n",
    "    :param is_train: Booleano si el generador está siendo utilizado para entrenamiento.\n",
    "    :return: El tensor de salida del generador\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('generator', reuse=not is_train):\n",
    "        start_dim = 512\n",
    "        kernel_sz = 5\n",
    "        strides = 2\n",
    "\n",
    "        layer_0 = tf.layers.dense(z, 7*7*start_dim)\n",
    "    \n",
    "        layer_0 = tf.reshape(layer_0, (-1, 7, 7, start_dim))\n",
    "        layer_0 = tf.layers.batch_normalization(layer_0, training=is_train)\n",
    "        # 7, 7, 512 \n",
    "      \n",
    "        layer_1 = tf.layers.conv2d_transpose(layer_0, int(start_dim/2), kernel_sz, \n",
    "                                             strides=strides, padding='same', \n",
    "                                             kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=True,\n",
    "                                                                                          seed=None,\n",
    "                                                                                          dtype=tf.float32\n",
    "                                                                                          )\n",
    "                                            )\n",
    "        layer_1 = tf.layers.batch_normalization(layer_1, training=is_train)\n",
    "        relu_1 = tf.maximum(alpha * layer_1, layer_1)\n",
    "        # 14, 14, 256\n",
    "    \n",
    "        layer_2 = tf.layers.conv2d_transpose(layer_1, int(start_dim/4), kernel_sz, strides=strides, padding='same')\n",
    "        layer_2 = tf.layers.batch_normalization(layer_2, training=is_train)\n",
    "        relu_2 = tf. maximum(alpha * layer_2, layer_2)\n",
    "        # 28, 28, 128\n",
    "        \n",
    "        layer_3 = tf.layers.conv2d_transpose(layer_2, int(start_dim/8), kernel_sz, strides=strides, padding='same')\n",
    "        layer_3 = tf.layers.batch_normalization(layer_3, training=is_train)\n",
    "        relu_3 = tf. maximum(alpha * layer_3, layer_3)\n",
    "        relu_3_d = tf.nn.dropout(relu_3, 0.8)\n",
    "        # 28, 28, 128\n",
    "\n",
    "    \n",
    "        logits = tf.layers.conv2d_transpose(relu_3_d, out_channel_dim, kernel_sz, strides=strides, padding='same')\n",
    "        logits = tf.reshape(logits, (-1, 28, 28, out_channel_dim))\n",
    "        # 28, 28, 5\n",
    "        output = tf.tanh(logits)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "# Funcion que calcula las perdidas del modelo    \n",
    "def model_loss(input_real, input_z, out_channel_dim):\n",
    "    \"\"\"\n",
    "    Calcula las perdidas del generados y el discriminador \n",
    "    :param input_real: Imagenes del dataset real\n",
    "    :param input_z: salida Z\n",
    "    :param out_channel_dim: Numero de canales en la imagen de salida\n",
    "    :return: Una tupla de (La perdida del discriminador, la perdida del generador)\n",
    "    \"\"\"\n",
    "    smooth = 0.1\n",
    "    alpha = 0.2\n",
    "    \n",
    "    # Generador con la salida Z\n",
    "    g_mod = generator(input_z, out_channel_dim, alpha=alpha)\n",
    "    \n",
    "    # discriminador con la entrada real y la salida g_mod\n",
    "    d_out_real, d_log_real = discriminator(input_real, alpha=alpha)\n",
    "    d_out_fake, d_log_fake = discriminator(g_mod, reuse=True, alpha=alpha)\n",
    "    \n",
    "    d_loss_real = tf.reduce_mean(\n",
    "                                tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                                    logits=d_log_real,\n",
    "                                    labels=tf.ones_like(d_out_real)*0.9\n",
    "                                 ))\n",
    "    \n",
    "    d_loss_fake = tf.reduce_mean(\n",
    "                                tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                                logits=d_log_fake,\n",
    "                                labels=tf.zeros_like(d_out_fake)))\n",
    "    \n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    \n",
    "    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_log_fake,\n",
    "                                                                 labels=tf.ones_like(d_out_fake)))\n",
    "    \n",
    "    \n",
    "    return (d_loss, g_loss)\n",
    "\n",
    "# Funcion que define el modelo de optimizacion \n",
    "def model_opt(d_loss, g_loss, learning_rate, beta1):\n",
    "    \"\"\"\n",
    "    Obtener operaciones de optimización\n",
    "    :param d_loss: Tensor de perdida del discriminador \n",
    "    :param g_loss: Tensor de perdida del generador\n",
    "    :param learning_rate: Placeholder de la tasa de aprendizaje\n",
    "    :param beta1: La tasa de decaimiento exponencial para el primer momento en el optimizador --> 0.9 (eg less than 1)\n",
    "    :return: Una tupla de (Operación de entrenamiento discriminador, Operación de entrenamiento generador)\n",
    "    \"\"\"\n",
    "    train_vars = tf.trainable_variables()\n",
    "    \n",
    "    #generador de variables de tamaño (3,3), float32\n",
    "    d_vars = [var for var in train_vars if var.name.startswith('discriminator')]\n",
    "    g_vars = [var for var in train_vars if var.name.startswith('generator')]\n",
    "    \n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        d_train_op = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "        g_train_op = tf.train.AdamOptimizer(learning_rate,beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
    "\n",
    "    return (d_train_op, g_train_op)\n",
    "\n",
    "\n",
    "# Se crea la funcion que muestra la salida del generador\n",
    "def show_generator_output(sess, n_images, input_z, out_channel_dim, image_mode, epoch, TotalPositivos, Total):\n",
    "    \"\"\"\n",
    "    Muestra un ejemplo de la salida del generador\n",
    "    :param sess: La seccion de Tensor flow\n",
    "    :param n_images: numero de imagenes que se mostraran\n",
    "    :param input_z: Entrada Z del tensor\n",
    "    :param out_channel_dim: Numero de canales de la imagen de salida\n",
    "    :param image_mode: El modo a utilizar para las imágenes (\"RGB\" o \"L\")\n",
    "    \"\"\"\n",
    "    \n",
    "    # Carpeta en donde se guardara las imagenes\n",
    "    sample_directory = './figs' \n",
    "    \n",
    "    cmap = None if image_mode == 'RGB' else 'gray'\n",
    "    z_dim = input_z.get_shape().as_list()[-1]\n",
    "    example_z = np.random.uniform(-1, 1, size=[n_images, z_dim])\n",
    "    # Se generan nuevas imagenes\n",
    "    samples = sess.run(\n",
    "        generator(input_z, out_channel_dim, False),\n",
    "        feed_dict={input_z: example_z})\n",
    "    # Se crea una grilla de imagenes\n",
    "    images_grid = helper1.images_square_grid(samples, image_mode)\n",
    "    # Se guarda la imagen en memoria\n",
    "    if not os.path.exists(sample_directory):\n",
    "        os.makedirs(sample_directory)\n",
    "    scipy.misc.imsave(sample_directory + '/fig' + '.png', images_grid)\n",
    "    print('Save image')\n",
    "    cont3 = 0\n",
    "    I4 = np.zeros([16, 28*28])\n",
    "    # Se carga la imagen previamente guardada\n",
    "    foto = Image.open(os.path.join(\"figs/\",\"fig.png\"))\n",
    "    \n",
    "    # Se recorda cada imagen de la grilla y se le aplica la trasformada de fourier\n",
    "    foto2 = foto.crop((1, 1, 28, 28))\n",
    "    \n",
    "    magnitude_spectrum2 = transformation(foto2)\n",
    "    \n",
    "    I4[cont3, :] = magnitude_spectrum2.ravel()\n",
    "    cont3 = cont3 + 1\n",
    "    \n",
    "    foto3 = foto.crop((28, 1, 56, 28))\n",
    "   \n",
    "    magnitude_spectrum2 = transformation(foto3)\n",
    "    \n",
    "    I4[cont3, :] = magnitude_spectrum2.ravel()\n",
    "    cont3 = cont3 + 1\n",
    "    \n",
    "    foto4 = foto.crop((56, 1, 84, 28))\n",
    "    magnitude_spectrum2 = transformation(foto4)\n",
    "    \n",
    "    I4[cont3, :] = magnitude_spectrum2.ravel()\n",
    "    cont3 = cont3 + 1\n",
    "    \n",
    "    foto4 = foto.crop((84, 1, 112, 28))\n",
    "    magnitude_spectrum2 = transformation(foto4)\n",
    "    \n",
    "    I4[cont3, :] = magnitude_spectrum2.ravel()\n",
    "    cont3 = cont3 + 1\n",
    "    \n",
    "    ##\n",
    "    foto2 = foto.crop((1, 28, 28, 56))\n",
    "    \n",
    "    magnitude_spectrum2 = transformation(foto2)\n",
    "    \n",
    "    I4[cont3, :] = magnitude_spectrum2.ravel()\n",
    "    cont3 = cont3 + 1\n",
    "    foto3 = foto.crop((28, 28, 56, 56))\n",
    "   \n",
    "    magnitude_spectrum2 = transformation(foto3)\n",
    "    \n",
    "    I4[cont3, :] = magnitude_spectrum2.ravel()\n",
    "    cont3 = cont3 + 1\n",
    "    \n",
    "    foto4 = foto.crop((56, 28, 84, 56))\n",
    "    magnitude_spectrum2 = transformation(foto4)\n",
    "    \n",
    "    I4[cont3, :] = magnitude_spectrum2.ravel()\n",
    "    cont3 = cont3 + 1\n",
    "    \n",
    "    foto4 = foto.crop((84, 28, 112, 56))\n",
    "    magnitude_spectrum2 = transformation(foto4)\n",
    "    \n",
    "    I4[cont3, :] = magnitude_spectrum2.ravel()\n",
    "    cont3 = cont3 + 1\n",
    "    \n",
    "    ##\n",
    "    \n",
    "    foto2 = foto.crop((1, 56, 28, 84))\n",
    "    \n",
    "    magnitude_spectrum2 = transformation(foto2)\n",
    "    \n",
    "    I4[cont3, :] = magnitude_spectrum2.ravel()\n",
    "    cont3 = cont3 + 1\n",
    "    foto3 = foto.crop((28, 56, 56, 84))\n",
    "   \n",
    "    magnitude_spectrum2 = transformation(foto3)\n",
    "    \n",
    "    I4[cont3, :] = magnitude_spectrum2.ravel()\n",
    "    cont3 = cont3 + 1\n",
    "    \n",
    "    foto4 = foto.crop((56, 56, 84, 84))\n",
    "    magnitude_spectrum2 = transformation(foto4)\n",
    "    \n",
    "    I4[cont3, :] = magnitude_spectrum2.ravel()\n",
    "    cont3 = cont3 + 1\n",
    "    \n",
    "    foto4 = foto.crop((84, 56, 112, 84))\n",
    "    magnitude_spectrum2 = transformation(foto4)\n",
    "    \n",
    "    I4[cont3, :] = magnitude_spectrum2.ravel()\n",
    "    cont3 = cont3 + 1\n",
    "    \n",
    "    ##\n",
    "    \n",
    "    foto2 = foto.crop((1, 84, 28, 112))\n",
    "    \n",
    "    magnitude_spectrum2 = transformation(foto2)\n",
    "    \n",
    "    I4[cont3, :] = magnitude_spectrum2.ravel()\n",
    "    cont3 = cont3 + 1\n",
    "    foto3 = foto.crop((28, 84, 56, 112))\n",
    "   \n",
    "    magnitude_spectrum2 = transformation(foto3)\n",
    "    \n",
    "    I4[cont3, :] = magnitude_spectrum2.ravel()\n",
    "    cont3 = cont3 + 1\n",
    "    \n",
    "    foto4 = foto.crop((56, 84, 84, 112))\n",
    "    magnitude_spectrum2 = transformation(foto4)\n",
    "    \n",
    "    I4[cont3, :] = magnitude_spectrum2.ravel()\n",
    "    cont3 = cont3 + 1\n",
    "    \n",
    "    foto4 = foto.crop((84, 84, 112, 112))\n",
    "    magnitude_spectrum2 = transformation(foto4)\n",
    "    \n",
    "    I4[cont3, :] = magnitude_spectrum2.ravel()\n",
    "    cont3 = cont3 + 1\n",
    "    \n",
    "    I4[I4 == -inf] = 100\n",
    "    # Se le aplica el PCA (previamente entrenado con los datos de entrenamiento)\n",
    "    X = pca.transform(I4)\n",
    "    # Se carga el modelo que reconoce caras, (previamente entrenado)\n",
    "    fid = open('Binary Model/Clasificador_de_caras_Furier.joblib.pkl', 'rb')\n",
    "    joblib_Model = joblib.load(fid)\n",
    "    # Se le pasa las imagenes creadas por la GAN\n",
    "    PrediccionTest = joblib_Model.predict(X)\n",
    "    pos = [1, 28, 56, 84, 112]\n",
    "    contx = 0\n",
    "    conty = 0\n",
    "    Total = Total + 16\n",
    "    # Se guardan solo aquellas que reconocio como caras\n",
    "    for i in range(0, 16):\n",
    "        if PrediccionTest[i] == 1:\n",
    "            TotalPositivos = TotalPositivos + 1\n",
    "            foto2 = foto.crop((pos[contx], pos[conty], pos[contx] + 28, pos[conty] + 28))\n",
    "            pyplot.imshow(foto2, cmap=cmap)\n",
    "            pyplot.show()\n",
    "            if not os.path.exists(sample_directory):\n",
    "                os.makedirs(sample_directory)\n",
    "            scipy.misc.imsave(sample_directory + '/fig_' + str(i) + '_epoch_' + str(epoch) + '.png', foto2)\n",
    "        contx = contx + 1\n",
    "        if contx == 5:\n",
    "            contx = 0; \n",
    "            conty = conty + 1\n",
    "    return TotalPositivos, Total\n",
    "\n",
    "# Se crea una funcion que hace la trasformada de furier y devuelve la matriz resultante\n",
    "def transformation(foto):\n",
    "    datos3 = foto.getdata()\n",
    "    #para el calculo del promedio se utilizara la division entera con el operador de division doble \"//\" para evitar decimales\n",
    "    promedio = [(datos3[x][0] + datos3[x][1] + datos3[x][2]) // 3 for x in range(len(datos3))]\n",
    "    imagen_gris3 = Image.new('L', foto.size)\n",
    "    imagen_gris3.putdata(promedio)\n",
    "    imagen_gris4 = imagen_gris3.resize((width, height), Image.NEAREST)\n",
    "    imagen_gris4 = np.array(imagen_gris4)\n",
    "    dft = cv2.dft(np.float32(imagen_gris4),flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "    dft_shift = np.fft.fftshift(dft)\n",
    "    magnitude_spectrum2 = 20*np.log(cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]))\n",
    "    \n",
    "    return magnitude_spectrum2\n",
    "\n",
    "# Se crea una funcion que entrenara la red GAN\n",
    "def train(epoch_count, batch_size, z_dim, learning_rate, beta1, get_batches,\n",
    "          data_shape, data_image_mode):\n",
    "    \"\"\"\n",
    "    Entrenamiento de la GAN\n",
    "    :param epoch_count: Numero de epocas\n",
    "    :param batch_size: Tamaño del batch\n",
    "    :param z_dim: dimencion de Z --> 100\n",
    "    :param learning_rate: Tasa de aprendizaje\n",
    "    :param beta1: La tasa de decaimiento exponencial para el primer momento en el optimizador\n",
    "    :param get_batches: Funcion para obtener los batches\n",
    "    :param data_shape: Tamaño de los datos --> (60000, 28, 28, 1)\n",
    "    :param data_image_mode: El modo de imagen a utilizar para imágenes (\"RGB\" o \"L\")\n",
    "    \"\"\"\n",
    "    # Carpeta en donde se guardara el modelo entrenado\n",
    "    model_directory = './models' \n",
    "    TotalPositivos = 0\n",
    "    Total = 0\n",
    "    steps = 0\n",
    "    div_by = 20\n",
    "    n_images = 10\n",
    "    image_mode=\"RGB\"\n",
    "    samples=[]\n",
    "    GenerativeLosss = 0\n",
    "    input_real, input_z, lr = model_inputs(data_shape[1], \n",
    "                                                      data_shape[2], \n",
    "                                                      data_shape[3], \n",
    "                                                      z_dim)\n",
    "    # --> Tensor(\"Placeholder:0\", shape=(?, 28, 28, 1), dtype=float32) \n",
    "    # Tensor(\"Placeholder_1:0\", shape=(?, 100), dtype=float32)\n",
    "    # Tensor(\"Placeholder_2:0\", dtype=float32)\n",
    "    z_batch_F = np.random.uniform(-1, 1, size=(1000, z_dim))        \n",
    "    d_loss, g_loss = model_loss(input_real, input_z, data_shape[3])\n",
    "    # --> Tensor(\"add:0\", shape=(), dtype=float32), Tensor(\"Mean_2:0\", shape=(), dtype=float32) \n",
    "    \n",
    "    d_train_op, g_train_op = model_opt(d_loss, g_loss, learning_rate, beta1)\n",
    "\n",
    "    init = tf.initialize_all_variables()\n",
    "    \n",
    "    # Se inicia la Seccion de tensor flow\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch_i in range(epoch_count):\n",
    "            start_time = time.time()\n",
    "            G_promedio = 0\n",
    "            cont = 0\n",
    "            for batch_images in get_batches(batch_size):\n",
    "                steps += 1\n",
    "                batch_images = batch_images * 2\n",
    "                # un simple ruido blanco\n",
    "                z_batch = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n",
    "                \n",
    "                # Enganchar optimizadores para discriminador y generador.\n",
    "                _ = sess.run(d_train_op, feed_dict={input_real: batch_images,\n",
    "                                                    input_z: z_batch, \n",
    "                                                    lr:learning_rate})\n",
    "                \n",
    "                _ = sess.run(d_train_op, feed_dict={input_real: batch_images,\n",
    "                                    input_z: z_batch, \n",
    "                                    lr:learning_rate})\n",
    "                \n",
    "                _ = sess.run(g_train_op, feed_dict={input_real: batch_images,\n",
    "                                                    input_z: z_batch,\n",
    "                                                    lr: learning_rate})\n",
    "                _ = sess.run(g_train_op, feed_dict={input_real: batch_images,\n",
    "                                    input_z: z_batch,\n",
    "                                    lr: learning_rate})\n",
    "                _ = sess.run(g_train_op, feed_dict={input_real: batch_images,\n",
    "                    input_z: z_batch,\n",
    "                    lr: learning_rate})\n",
    "        \n",
    "            \n",
    "                # Se optiene la perdida del generado y discriminador para imprimirla\n",
    "                G_promedio = G_promedio + g_loss.eval({input_z: z_batch})\n",
    "                cont = cont + 1\n",
    "                if steps % 50 == 0:\n",
    "                    d_train_loss = d_loss.eval({input_real: batch_images, input_z: z_batch})\n",
    "                    g_train_loss = g_loss.eval({input_z: z_batch})\n",
    "                    \n",
    "\n",
    "                    print(\"Epoch {}/{} {} steps\".format(epoch_i+1, epoch_count, steps), \n",
    "                         \"- training losses: \"\n",
    "                         \" discriminator: {:.4f}\".format(d_train_loss),\n",
    "                         \"| generator {:.4f}\".format(g_train_loss))\n",
    "                    # Se llama la funcion que genera una nueva cara\n",
    "                    if steps % 300 == 0:\n",
    "                        if data_shape[3] == 1:\n",
    "                            image_mode= \"L\"\n",
    "                        TotalPositivos, Total = show_generator_output(sess, 1, input_z, data_shape[3], image_mode, epoch_i, TotalPositivos, Total)\n",
    "                        print('Total de datos: ' + str(Total) + ', Total aciertos: ' + str(TotalPositivos))\n",
    "                        print('Porcentaje exitos: ' + str(TotalPositivos/Total))\n",
    "            #d_train_loss = d_loss.eval({input_real: batch_images, input_z: z_batch})\n",
    "            G_promedio = G_promedio/cont\n",
    "            print('promedio generator loss: ' + str(G_promedio))\n",
    "            # Se guarda el modelo con mejor perdida en el generador\n",
    "            if GenerativeLosss < G_promedio:\n",
    "                file = open('Generative_loss.txt', 'w')\n",
    "                file.write(str(epoch_i) + ': ' + str(g_train_loss))\n",
    "                file.close()\n",
    "                GenerativeLosss = g_train_loss\n",
    "                saver = tf.train.Saver()\n",
    "                if not os.path.exists(model_directory):\n",
    "                    os.makedirs(model_directory)\n",
    "                saver.save(sess,model_directory+'/model-' + str(epoch_i) + '.cptk')\n",
    "                print(\"Saved Model\") \n",
    "            # Se calcula el tiempo de ejecucion de la epoca    \n",
    "            Elapse = time.time() - start_time\n",
    "            print(\"Time of simulation epoch\" + str(epoch_i) + \": \" + str(Elapse))\n",
    "            # Se deja descansar el procesador por un minuto\n",
    "            time.sleep(60)\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # Se cargan los dataset de entrenamiento \n",
    "    data_dir = '/input/R5KrjnANiKVhLWAkpXhNBe'\n",
    "\n",
    "    # mnist es el dataset de numeros\n",
    "    helper1.download_extract('mnist', data_dir)\n",
    "    # celeba es el dataset de caras\n",
    "    helper1.download_extract('celeba', data_dir)\n",
    "\n",
    "    # Se carga 25 imagenes del dataset de numeros para mostrarlos en una grilla, estas imagenes se escalan a 28x28\n",
    "    show_n_images = 25\n",
    "    mnist_images = helper1.get_batch(glob(os.path.join(data_dir, 'mnist/*.jpg'))[:show_n_images], 28, 28, 'L')\n",
    "    pyplot.imshow(helper1.images_square_grid(mnist_images, 'L'), cmap='gray')\n",
    "\n",
    "    # Se carga 4 imagenes del dataset de caras para mostrarlos en una grilla, estas imagenes se escalan a 28x28\n",
    "    show_n_images = 4\n",
    "    mnist_images = helper1.get_batch(glob(os.path.join(data_dir, 'img_align_celeba/*.jpg'))[:show_n_images], 28, 28, 'RGB')\n",
    "    pyplot.imshow(helper1.images_square_grid(mnist_images, 'RGB'))\n",
    "\n",
    "    # Se verifica la version del tensorflow\n",
    "    assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "    print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "    # Se verifica si hay disponible una GPU\n",
    "    if not tf.test.gpu_device_name():\n",
    "        warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "    else:\n",
    "        print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))        \n",
    "\n",
    "    # nombre de la carpeta que contiene el Dataset de caras (el que se utilizo para el entrenamiento del SVM)\n",
    "    carpeta = \"1Dataset/\"\n",
    "    cont = 0\n",
    "    width = 28\n",
    "    height = 28\n",
    "    # Se crea un arreglo de ceros del tamaño n_imagesx28x28\n",
    "    for archivo in os.listdir(carpeta):\n",
    "        cont = cont + 1\n",
    "    I2 = np.zeros([cont, width, height])\n",
    "    cont = 0\n",
    "    # Se rellena el arreglo con la informacion de las imagenes\n",
    "    for archivo in os.listdir(carpeta):\n",
    "        # Se lee la imagen y se gurda su informacion\n",
    "        foto = Image.open(os.path.join(carpeta,archivo))\n",
    "        datos = foto.getdata()\n",
    "\n",
    "        # Se convierte en escala de grises   \n",
    "        promedio = [(datos[x][0] + datos[x][1] + datos[x][2]) // 3 for x in range(len(datos))]\n",
    "        imagen_gris = Image.new('L', foto.size)\n",
    "        imagen_gris.putdata(promedio)\n",
    "        # Se reescala a 28x28\n",
    "        imagen_gris2 = imagen_gris.resize((width, height), Image.NEAREST) \n",
    "        # Se le hace la trasformada de furier\n",
    "        imagen_gris2 = np.array(imagen_gris2)\n",
    "        dft = cv2.dft(np.float32(imagen_gris2),flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "        dft_shift = np.fft.fftshift(dft)\n",
    "        magnitude_spectrum2 = 20*np.log(cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]))\n",
    "        I2[cont, :, :] = magnitude_spectrum2\n",
    "        cont = cont + 1\n",
    "\n",
    "    # Se convierte las matrices de 28x28 a un vector de 1x784\n",
    "\n",
    "    I3 = np.zeros([cont, width * height])\n",
    "    for i in range(0, cont):\n",
    "        I3[i, :] = I2[i, :, :].ravel()\n",
    "    # Se selecionan las primeras 10000 para entrenar el PCA\n",
    "    X_train = I3[:10000, :]\n",
    "    X_train[X_train == -inf] = 100\n",
    "\n",
    "    pca = PCA(n_components=400, whiten=True)\n",
    "    pca = pca.fit(X_train)\n",
    "    print('Explained variance percentage = %0.2f' % sum(pca.explained_variance_ratio_))\n",
    "\n",
    "    # Se establecen los parametros del modelo\n",
    "    batch_size = 32\n",
    "    z_dim = 100 \n",
    "    learning_rate = 0.0002\n",
    "    beta1 = 0.3\n",
    "\n",
    "    epochs = 50\n",
    "    # Se carga el data set de caras (Celeba)\n",
    "    celeba_dataset = helper1.Dataset('celeba', glob(os.path.join(data_dir, 'img_align_celeba/*.jpg')))\n",
    "    # Se inicializa al grafo de tensor flow y se ejecuta el entrenamiento \n",
    "    with tf.Graph().as_default():\n",
    "        train(epochs, batch_size, z_dim, learning_rate, beta1, celeba_dataset.get_batches,\n",
    "              celeba_dataset.shape, celeba_dataset.image_mode)\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
